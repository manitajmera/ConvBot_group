{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data processing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2-3BXwxbqv9",
        "colab_type": "code",
        "outputId": "7efaa97d-94b7-4434-d3e8-6b608e6d5fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8sOsg1oC-To",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "db895971-e6b6-470e-bed9-01fd3831f195"
      },
      "source": [
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import codecs\n",
        "import fnmatch\n",
        "import os\n",
        "import sys\n",
        "import tarfile\n",
        "import tempfile\n",
        "import unicodedata\n",
        "\n",
        "import pandas\n",
        "from six.moves import urllib\n",
        "!pip install pydub\n",
        "!pip install  ffmpeg\n",
        "from os.path import splitext\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.6/dist-packages (0.24.0)\n",
            "Requirement already satisfied: ffmpeg in /usr/local/lib/python3.6/dist-packages (1.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM3CSoVfX5gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LIBRI_SPEECH_URLS = {\n",
        "    \"train-clean-100\":\n",
        "        \"http://www.openslr.org/resources/12/train-clean-100.tar.gz\"\n",
        "}\n",
        "\n",
        "def download_and_extract(directory, url):\n",
        "  \"\"\"Download and extract the given split of dataset.\n",
        "  Args:\n",
        "    directory: the directory where to extract the tarball.\n",
        "    url: the url to download the data file.\n",
        "  \"\"\"\n",
        "\n",
        "  if not tf.gfile.Exists(directory):\n",
        "    tf.gfile.MakeDirs(directory)\n",
        "\n",
        "  _, tar_filepath = tempfile.mkstemp(suffix=\".tar.gz\")\n",
        "\n",
        "  try:\n",
        "    tf.logging.info(\"Downloading %s to %s\" % (url, tar_filepath))\n",
        "\n",
        "    def _progress(count, block_size, total_size):\n",
        "      sys.stdout.write(\"\\r>> Downloading {} {:.1f}%\".format(\n",
        "          tar_filepath, 100.0 * count * block_size / total_size))\n",
        "      sys.stdout.flush()\n",
        "\n",
        "    urllib.request.urlretrieve(url, tar_filepath, _progress)\n",
        "    print()\n",
        "    statinfo = os.stat(tar_filepath)\n",
        "    tf.logging.info(\n",
        "        \"Successfully downloaded %s, size(bytes): %d\" % (url, statinfo.st_size))\n",
        "    with tarfile.open(tar_filepath, \"r\") as tar:\n",
        "      tar.extractall(directory)\n",
        "  finally:\n",
        "    tf.gfile.Remove(tar_filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Ng58YkX1vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_audio_and_split_transcript(input_dir, source_name, target_name,\n",
        "                                       output_dir, output_file):\n",
        "  \"\"\"Convert FLAC to WAV and split the transcript.\n",
        "  For audio file, convert the format from FLAC to WAV using the sox.Transformer\n",
        "  library.\n",
        "  For transcripts, each line contains the sequence id and the corresponding\n",
        "  transcript (separated by space):\n",
        "  Input data format: seq-id transcript_of_seq-id\n",
        "  For example:\n",
        "   1-2-0 transcript_of_1-2-0.flac\n",
        "   1-2-1 transcript_of_1-2-1.flac\n",
        "   ...\n",
        "  Each sequence id has a corresponding .flac file.\n",
        "  Parse the transcript file and generate a new csv file which has three columns:\n",
        "  \"wav_filename\": the absolute path to a wav file.\n",
        "  \"wav_filesize\": the size of the corresponding wav file.\n",
        "  \"transcript\": the transcript for this audio segement.\n",
        "  Args:\n",
        "    input_dir: the directory which holds the input dataset.\n",
        "    source_name: the name of the specified dataset. e.g. test-clean\n",
        "    target_name: the directory name for the newly generated audio files.\n",
        "                 e.g. test-clean-wav\n",
        "    output_dir: the directory to place the newly generated csv files.\n",
        "    output_file: the name of the newly generated csv file. e.g. test-clean.csv\n",
        "  \"\"\"\n",
        "\n",
        "  tf.logging.info(\"Preprocessing audio and transcript for %s\" % source_name)\n",
        "  source_dir = os.path.join(input_dir, source_name)\n",
        "  target_dir = os.path.join(input_dir, target_name)\n",
        "\n",
        "  if not tf.gfile.Exists(target_dir):\n",
        "    tf.gfile.MakeDirs(target_dir)\n",
        "\n",
        "  files = []\n",
        "  tfm = Transformer()\n",
        "  # Convert all FLAC file into WAV format. At the same time, generate the csv\n",
        "  # file.\n",
        "  for root, _, filenames in tf.gfile.Walk(source_dir):\n",
        "    for filename in fnmatch.filter(filenames, \"*.trans.txt\"):\n",
        "      trans_file = os.path.join(root, filename)\n",
        "      with codecs.open(trans_file, \"r\", \"utf-8\") as fin:\n",
        "        for line in fin:\n",
        "          seqid, transcript = line.split(\" \", 1)\n",
        "          # We do a encode-decode transformation here because the output type\n",
        "          # of encode is a bytes object, we need convert it to string.\n",
        "          transcript = unicodedata.normalize(\"NFKD\", transcript).encode(\n",
        "              \"ascii\", \"ignore\").decode(\"ascii\", \"ignore\").strip().lower()\n",
        "\n",
        "          # Convert FLAC to WAV.\n",
        "\n",
        "          def flac2wav(flac_file):\n",
        "            wav_path = os.path.join(target_dir, seqid + \".wav\")\n",
        "            song = AudioSegment.from_file(flac_file,format=\"flac\")\n",
        "            song.export(wav_path, format = \"wav\")\n",
        "          flac_file = os.path.join(root, seqid + \".flac\")\n",
        "          #print(flac_file)\n",
        "          #print(splitext(flac_file)[0])\n",
        "          wav_file = os.path.join(target_dir, seqid + \".wav\")\n",
        "          print(wav_file)\n",
        "          if not tf.gfile.Exists(wav_file):\n",
        "            flac2wav(flac_file)\n",
        "          wav_filesize = os.path.getsize(wav_file)\n",
        "          files.append((os.path.abspath(wav_file), wav_filesize, transcript)) \n",
        "\n",
        "  # Write to CSV file which contains three columns:\n",
        "  # \"wav_filename\", \"wav_filesize\", \"transcript\".\n",
        "  csv_file_path = os.path.join(output_dir, output_file)\n",
        "  df = pandas.DataFrame(\n",
        "      data=files, columns=[\"wav_filename\", \"wav_filesize\", \"transcript\"])\n",
        "  df.to_csv(csv_file_path, index=False, sep=\"\\t\")\n",
        "  tf.logging.info(\"Successfully generated csv file {}\".format(csv_file_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au0AI3cOYO5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_and_process_datasets(directory, datasets):\n",
        "  \"\"\"Download and pre-process the specified list of LibriSpeech dataset.\n",
        "  Args:\n",
        "    directory: the directory to put all the downloaded and preprocessed data.\n",
        "    datasets: list of dataset names that will be downloaded and processed.\n",
        "  \"\"\"\n",
        "\n",
        "  tf.logging.info(\"Preparing LibriSpeech dataset: {}\".format(\n",
        "      \",\".join(datasets)))\n",
        "  for dataset in datasets:\n",
        "    tf.logging.info(\"Preparing dataset %s\", dataset)\n",
        "    dataset_dir = os.path.join(directory, dataset)\n",
        "    download_and_extract(dataset_dir, LIBRI_SPEECH_URLS[dataset])\n",
        "    convert_audio_and_split_transcript(\n",
        "        dataset_dir + \"/LibriSpeech\", dataset, dataset + \"-wav\",\n",
        "        dataset_dir + \"/LibriSpeech\", \n",
        "        dataset + \".csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIwNLscYYqnp",
        "colab_type": "code",
        "outputId": "ac37573b-56d7-4fbe-996f-c685476dbada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        }
      },
      "source": [
        "#EXECUTION STARTS FROM HERE\n",
        "tf.gfile.MakeDirs(\"/tmp/librispeech_data\")\n",
        "download_and_process_datasets(\"/tmp/librispeech_data\",[\"train-clean-100\"])\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Preparing LibriSpeech dataset: train-clean-100\n",
            "INFO:tensorflow:Preparing dataset train-clean-100\n",
            "INFO:tensorflow:Downloading http://www.openslr.org/resources/12/train-clean-100.tar.gz to /tmp/tmpoql2j6hy.tar.gz\n",
            ">> Downloading /tmp/tmpoql2j6hy.tar.gz 100.0%\n",
            "INFO:tensorflow:Successfully downloaded http://www.openslr.org/resources/12/train-clean-100.tar.gz, size(bytes): 6387309499\n",
            "INFO:tensorflow:Preprocessing audio and transcript for train-clean-100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-a05e2c20ea0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/librispeech_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownload_and_process_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/librispeech_data\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train-clean-100\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-c6986a1f3360>\u001b[0m in \u001b[0;36mdownload_and_process_datasets\u001b[0;34m(directory, datasets)\u001b[0m\n\u001b[1;32m     14\u001b[0m     convert_audio_and_split_transcript(\n\u001b[1;32m     15\u001b[0m         \u001b[0mdataset_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/LibriSpeech\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-wav\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         dataset_dir + \"/LibriSpeech\", dataset + \".csv\")\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-3e20ec3ae392>\u001b[0m in \u001b[0;36mconvert_audio_and_split_transcript\u001b[0;34m(input_dir, source_name, target_name, output_dir, output_file)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mflac2wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflac_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mwav_filesize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwav_filesize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/librispeech_data/train-clean-100/LibriSpeech/train-clean-100-wav/4788-94904-0039.wav'"
          ]
        }
      ]
    }
  ]
}